d.train = read.csv("training.csv", stringsAsFactors=F)
im.train = d.train$Image
d.train$Image = NULL

#for parallel computing, install foreach

install.packages("foreach")
library(foreach)

#seperate string representation of images into int for pixel representation
im.train = foreach(im = im.train, .combine=rbind) %do% {
as.integer(unlist(strsplit(im," "))) }
d.test = read.csv("test.csv", stringsAsFactors = F)
im.test = foreach(im = d.test$Image, .combine = rbind) %do% {
as.integer(unlist(strsplit(im," "))) }
d.test$Image = NULL;

#list of facial feature keypoints
keypoint.names = gsub("_x", "", names(d.train)[grep("_x", names(d.train))])
#size of area snapshot and scanning length
patch_size=10
search_size=2

#for every facial feature find the average area
average.areas=foreach(coord=keypoint.names) %do% {
  coordinate_x = paste(coord, "x", sep="_")
  coordinate_y = paste(coord, "y", sep="_")
  area = foreach(i=1:nrow(d.train), .combine=rbind) %do% {
    im = matrix(data=im.train[i,], nrow=96, ncol=96)
    x=d.train[i,coordinate_x]
    y=d.train[i,coordinate_y]
    x1=(x-patch_size)
    x2=(x+patch_size)
    y1=(y-patch_size)
    y2=(y+patch_size)
  
  if ( (!is.na(x)) && (!is.na(y)) && (x1>=1) && (x2<=96) && (y1>=1) && (y2<=96) )
		{
			as.vector(im[x1:x2, y1:y2])
		}
    
  else
  {
  NULL
  }
  
  }
  matrix(data=colMeans(area),nrow=2*patch_size+1,ncol=2*patch_size+1)
  }
  
  #find position that best correlates to the average patch of a facial feature
  pos = foreach(coordinate_i = 1:length(coordinate.names), .combine=cbind) %do%
  {
  coordinate = coordinate.names[coordinate_i]
  coordinate_x = paste(coordinate, "x", sep="_")
  coordinate_y = paste(coordinate, "y", sep="_")
  
  average_x=mean(d.train[,coord_x], na.rm=T)
  average_y=mean(d.train[,coord_y],na.rm=T)
  
  x1=as.integer(average_x)-search_size
  x2=as.integer(average_x)+search_size
  y1=as.integer(average_y)-search_size
  y2=as.integer(average_y)+search_size
  
  x1=ifelse(x1-patch_size<1, patch_size+1, x1)
  x2=ifelse(x2+patch_size>96, 96-patch_size, x2)
  y1=ifelse(y1-patch_size<1, patch_size+1, y1)
  y2 = ifelse(y2+patch_size>96, 96-patch_size, y2)
  
  all_parameters = expand.grid(x = x1:x2, y = y2:y2)
  
  score = foreach(current_image = 1:nrow(d.test), .combine=rbind) %do%
  {
  if((coordinate_i==1)&&((i%%100)==0)) {cat(sprintf("%d/%d\n",i,nrow(d.test))) }
  im = matrix(data=im.test[i,], nrow=96, ncol=96)
  	#ever position will need a score 
	score = foreach(j = 1:nrow(params), .combine=rbind) %do%
	{
	x=params$x[j]
	y=params$y[j]
	pos=im[(x-patch_size):(x+patch_size),(y-patch_size):(y+patch_size)]
	score = cor(as.vector(p), as.vector(mean.patches[[coordinate_i]]))
	score = ifelse(is.na(score),0,score)
	data.frame(x,y,score)
	}
	
	best_score = r[which.max(r$score),c("x","y")]
	}
	names(r) = c(coordinate_x,coordinate_y)
	r
	}
	
#submission file

final_prediction=data.frame(ImageID=1:nrow(d.test),p)
final_submission=melt(predictions, id.vars="ImageId", variable.name="FeatureName", value.name="Location")
example.submission=read.csv(paste0(data.dir, 'submissionFileFormat.csv'))
sub.col.names=names(example.submission)
example.submission$Location=NULL
final_submission=merge(example.submission, submission, all.x=T, sort=F)
final_submission=submission[, sub.col.names]
write.csv(final_submission, file="submission_search.csv", quote=F, row.names=F)



  
  
  
  
